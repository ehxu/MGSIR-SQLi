"""
XGBoostè®­ç»ƒå™¨é‡æ„

ä¿æŒåŸæœ‰æ¥å£ï¼štrain_and_save_xgb_model()
åŸºäºç»Ÿä¸€çš„åŸºç±»å®ç°ï¼Œæé«˜ä»£ç å¤ç”¨æ€§
"""

import os
import joblib
import time
import numpy as np
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score
from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBClassifier

from pathlib import Path
from src.config.model_config import get_xgb_config
from src.config.paths import get_pipeline_paths


# ==================== å·¥å…·å‡½æ•° ====================
def find_best_threshold(proba_vals, true_labels, steps=101):
    """åœ¨ 0~1 æœç´¢æœ€ä½³é˜ˆå€¼ä»¥æœ€å¤§åŒ– F1"""
    best_thr, best_f1 = 0.5, 0.0

    for thr in np.linspace(0, 1, steps):
        preds = (proba_vals >= thr).astype(int)
        f1 = f1_score(true_labels, preds)
        if f1 > best_f1:
            best_f1 = f1
            best_thr = thr

    return best_thr, best_f1


# ==================== è®­ç»ƒå™¨åŸºç±» ====================
class BaseTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨åŸºç±»"""
    
    def __init__(self, pipeline_name: str, base_dir: Path, logger=None):
        self.pipeline_name = pipeline_name
        self.base_dir = Path(base_dir)
        self.logger = logger
        
        # è·¯å¾„è®¾ç½®
        self.model_dir = self.base_dir / "model"
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        self.model_file = self.model_dir / f"{pipeline_name}_model.pkl"
        self.thr_file = self.model_dir / f"{pipeline_name}_threshold.pkl"
        
    def log(self, message: str):
        """æ—¥å¿—è®°å½•"""
        if self.logger:
            self.logger.info(message)
        else:
            print(message)
    
    def _create_model(self, **kwargs):
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        return XGBClassifier(**kwargs)
    
    def _search_params(self, train_x, train_y, param_space, search_cfg):
        """å‚æ•°æœç´¢"""
        model = self._create_model(**search_cfg.get('base_params', {}))
        searcher = RandomizedSearchCV(model, param_space, **search_cfg)
        searcher.fit(train_x, train_y)
        return searcher.best_params_
    
    def train(self, 
              train_x, train_y, 
              val_x, val_y,
              base_params: dict,
              search_config: dict = None,
              param_space: dict = None,
              use_best_threshold: bool = False,
              threshold_steps: int = 101) -> dict:
        """ç»Ÿä¸€çš„æ¨¡å‹è®­ç»ƒæµç¨‹"""
        start_total_time = time.time()
        self.log(f"\n{'='*20} XGBoost Trainer ({self.pipeline_name}) å¯åŠ¨ {'='*20}")
        self.log(f"[CONFIG] åŸºç¡€å‚æ•°: {base_params}")
        
        # å‚æ•°æœç´¢æˆ–ä½¿ç”¨å›ºå®šå‚æ•°
        best_params = {}
        search_duration = 0.0
        
        if search_config and param_space:
            self.log(f"[INFO] å¼€å§‹å‚æ•°æœç´¢ï¼Œæœç´¢é…ç½®: {search_config}")
            start_search_time = time.time()
            
            best_params = self._search_params(train_x, train_y, param_space, search_config)
            
            search_duration = time.time() - start_search_time
            self.log(f"[INFO] æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_duration:.2f}s")
            self.log(f"[INFO] æœ€ä¼˜å‚æ•°: {best_params}")
        else:
            self.log(f"ğŸš€ [Fast Mode] ä½¿ç”¨é¢„è®¾å›ºå®šå‚æ•°ï¼Œè·³è¿‡æœç´¢")
        
        # åˆå¹¶å‚æ•°
        final_params = base_params.copy()
        final_params.update(best_params)
        self.log(f"[INFO] æœ€ç»ˆè®­ç»ƒå‚æ•°: {final_params}")
        
        # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        self.log(f"[INFO] å¼€å§‹è®­ç»ƒæœ€ç»ˆæ¨¡å‹...")
        start_train_time = time.time()
        
        model = self._create_model(**final_params)
        model.fit(
            train_x, train_y, 
            eval_set=[(train_x, train_y), (val_x, val_y)], 
            verbose=False
        )
        
        train_duration = time.time() - start_train_time
        self.log(f"[INFO] æœ€ç»ˆæ¨¡å‹è®­ç»ƒè€—æ—¶: {train_duration:.2f}s")
        
        # è¯„ä¼°æ¨¡å‹
        metrics = self._evaluate_model(model, train_x, train_y, val_x, val_y)
        
        # é˜ˆå€¼æœç´¢
        best_threshold = None
        if use_best_threshold:
            self.log("[INFO] æœç´¢æœ€ä½³é˜ˆå€¼...")
            val_proba = model.predict_proba(val_x)[:, 1]
            best_threshold, best_f1 = find_best_threshold(val_proba, val_y, threshold_steps)
            metrics["best_threshold"] = best_threshold
            metrics["f1_val_best_threshold"] = best_f1
            self.log(f"[INFO] æœ€ä½³é˜ˆå€¼: {best_threshold:.4f} -> F1: {best_f1:.4f}")
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(model, self.model_file)
        self.log(f"[SAVE] æ¨¡å‹å·²ä¿å­˜ï¼š{self.model_file}")
        
        # è®¡ç®—æ¨¡å‹å¤§å°
        try:
            model_size_bytes = os.path.getsize(self.model_file)
            model_size_mb = model_size_bytes / (1024 * 1024)
            self.log(f"[INFO] æ¨¡å‹å¤§å°: {model_size_mb:.2f} MB")
        except Exception as e:
            self.log(f"[WARN] æ— æ³•è®¡ç®—æ¨¡å‹å¤§å°: {e}")
            model_size_mb = -1.0
        
        # ä¿å­˜é˜ˆå€¼
        if best_threshold is not None:
            joblib.dump(best_threshold, self.thr_file)
            self.log(f"[SAVE] é˜ˆå€¼å·²ä¿å­˜ï¼š{self.thr_file}")
        
        total_duration = time.time() - start_total_time
        self.log(f"========== è®­ç»ƒå®Œæˆ (æ€»è€—æ—¶: {total_duration:.2f}s) ==========\n")
        self.log(f"[FULL METRICS] {metrics}")
        
        return {
            "model_name": "xgb",
            "best_params": best_params,
            "metrics": metrics,
            "model_path": str(self.model_file),
            "thr_path": str(self.thr_file),
            "threshold": best_threshold,
            "val_f1": metrics.get("val_default_f1", 0.0),
            "val_acc": metrics.get("val_default_acc", 0.0),
            "train_time_sec": train_duration + search_duration,
            "model_size_mb": model_size_mb,
        }
    
    def _evaluate_model(self, model, train_x, train_y, val_x, val_y) -> dict:
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        # é¢„æµ‹
        pred_train = model.predict(train_x)
        pred_val = model.predict(val_x)
        
        # è®¡ç®—æŒ‡æ ‡
        def calc_metrics(y_true, y_pred, prefix):
            return {
                f"{prefix}_f1": f1_score(y_true, y_pred),
                f"{prefix}_acc": accuracy_score(y_true, y_pred),
                f"{prefix}_prec": precision_score(y_true, y_pred),
                f"{prefix}_rec": recall_score(y_true, y_pred),
            }
        
        metrics_train = calc_metrics(train_y, pred_train, "train_default")
        metrics_val = calc_metrics(val_y, pred_val, "val_default")
        
        # åˆå¹¶æŒ‡æ ‡
        metrics = {**metrics_train, **metrics_val}
        
        # æ‰“å°å…³é”®æŒ‡æ ‡
        self.log(f"{'='*20} [RESULT] Train Metrics (Default) {'='*20}")
        self.log(f"F1 Score : {metrics['train_default_f1']:.4f} | Accuracy : {metrics['train_default_acc']:.4f}")
        
        self.log(f"{'='*20} [RESULT] Validation Metrics (Default) {'='*20}")
        self.log(f"F1 Score : {metrics['val_default_f1']:.4f} | Accuracy : {metrics['val_default_acc']:.4f}")
        self.log(f"Precision: {metrics['val_default_prec']:.4f} | Recall   : {metrics['val_default_rec']:.4f}")
        
        return metrics


# ==================== åŸæœ‰æ¥å£å‡½æ•°ï¼ˆä¿æŒå…¼å®¹ï¼‰ ====================
def train_and_save_xgb_model(
    train_x,
    train_y,
    val_x,
    val_y,
    model_cfg,
    pipeline_name,
    logger=None,
    sub_dir: str = None,
):
    """
    XGBoostè®­ç»ƒä¸»å‡½æ•°
    
    ä¿æŒåŸæœ‰æ¥å£ä¸å˜ï¼Œå†…éƒ¨ä½¿ç”¨é‡æ„åçš„ç±»å®ç°
    """
    # è·å– pipeline paths
    paths = get_pipeline_paths(pipeline_name, sub_dir=sub_dir)
    
    # åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹
    trainer = BaseTrainer(pipeline_name, paths.base_dir, logger)
    
    # è·å–é…ç½®
    base_params = model_cfg["base_params"]
    specific_cfg = get_xgb_config(pipeline_name)
    
    # å‡†å¤‡å‚æ•°
    search_config = None
    param_space = None
    
    if specific_cfg.get("search") is False:
        # æé€Ÿæ¨¡å¼ï¼šä½¿ç”¨å›ºå®šå‚æ•°
        best_params = specific_cfg["params"]
        # åˆå¹¶å‚æ•°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        final_params = base_params.copy()
        final_params.update(best_params)
        
        # ç›´æ¥è®­ç»ƒï¼Œä¸æœç´¢
        return trainer.train(
            train_x, train_y, val_x, val_y,
            base_params=final_params,
            search_config=None,
            param_space=None,
            use_best_threshold=model_cfg.get("use_best_threshold", False),
            threshold_steps=model_cfg.get("threshold_steps", 101)
        )
    else:
        # æœç´¢æ¨¡å¼
        search_config = model_cfg["search"]
        param_space = model_cfg["param_space"]
        
        return trainer.train(
            train_x, train_y, val_x, val_y,
            base_params=base_params,
            search_config=search_config,
            param_space=param_space,
            use_best_threshold=model_cfg.get("use_best_threshold", False),
            threshold_steps=model_cfg.get("threshold_steps", 101)
        )
